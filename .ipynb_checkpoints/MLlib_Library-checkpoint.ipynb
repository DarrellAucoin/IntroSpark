{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Machine Learning Library (MLlib)\n",
    "Spark machine learning library of common learning algorithms and utilities: classification, regression, collaborative filtering, dimensinoality reduction, and some optimization algorithms.\n",
    "\n",
    "API is divided into 2 parts:\n",
    "1. `spark.mlib` API as the main API\n",
    "2. `spark.ml` as a higher-level API for workflows\n",
    "\n",
    "##Data Types\n",
    "MLib uses vectors, labeled points (for classification) and matrices.  \n",
    "\n",
    "__Local Vector__: A vector of numberical values. A vector can be either dense (very few zeros) or sparse (alot of zero values).\n",
    "- For python API, numpy arrays and lists can be used for vectors\n",
    "- For sparce Vectors, use MLlib's `SparseVector` or scipy's `csc_matrix` with a single column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DenseVector([1.0, 2.0, 3.0])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.mllib.linalg import Vectors\n",
    "vec = Vectors.dense([1, 2, 3])\n",
    "vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SparseVector(3, {0: 1.0, 2: 3.0})"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sparceVec = Vectors.sparse(3, {0:1.0, 2:3.0})\n",
    "sparceVec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These vectors can be indexed, take their dot product, find it's norm, find the squared distance between it and another vector, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.0"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vec[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sparceVec[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10.0"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vec.dot(sparceVec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.0"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vec.squared_distance(sparceVec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Labeled Point__: A labeled point is a vector associated with a label/response. The label must be able to be parsed into a float.\n",
    "\n",
    "- For classification, the labels should be integers going from 0 to k-1, where k is the number of classifications. Binary classification should be either 0 or 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LabeledPoint(1.0, [1.0,2.0,3.0])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.mllib.regression import LabeledPoint\n",
    "pos = LabeledPoint(1, vec)\n",
    "pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LabeledPoint(2.0, (3,[1,3],[1.0,3.0]))"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos2 = LabeledPoint(2, sparceVec)\n",
    "pos2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These LabeledPoints have two attributes: label, and features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label 1.0 with feature [1.0,2.0,3.0]\n"
     ]
    }
   ],
   "source": [
    "print \"Label {0} with feature {1}\" \\\n",
    "    .format(pos.label, pos.features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Matrices__: Matrices can be located on a single machine or distributed over the cluster. There are several ways of storing a distributed matrix, each with their own advantages/disadvantages.\n",
    "1. __Local Matrix__: Integer-typed row and column indices that is stored on single machine.\n",
    "2. __RowMatrix__: A row-orientated distributed matrix without meaningful row indices. The number of columns must not be too large.\n",
    "3. __IndexedRowMatrix__: A row-orientated distributed matrix with row indices.\n",
    "4. __CoordinateMatrix__: A distributed matrix where each entry is stored as a tuple (i,j,v) where i is the row, j is the column, and v is the entry value. This should be only used when $n$ and $m$ are large and the matrix is sparse.\n",
    "5. __BlockMatrix__: A distributed matrix where a MatrixBlock is a tuple ((i,j), matrix), where i and j are the index for the block and matrix is the submatrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pyspark.mllib.linalg import DenseMatrix\n",
    "DenseMatrix?\n",
    "from pyspark.mllib.linalg.Matrices.dense?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pyspark.mllib.linalg import Matrix\n",
    "m = Matrix?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "m = Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "m = Matrix.mro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.mllib.linalg import SparseMatrix\n",
    "SparseMatrix?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.mllib.linalg import Matrices\n",
    "Matrices.dense?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.mllib.linalg.Matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k = DenseMatrix(2, 2, [1,2,3,4], isTransposed=False)\n",
    "k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.mllib.linalg import Vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Vectors.sparse?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pyspark.mllib.linalg import array\n",
    "l = array.array(\"B\", [1,2,3,4])\n",
    "l.tolist?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
